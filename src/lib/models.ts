import { ModelCapabilities } from "../types";

export const anthropicModels: ModelCapabilities[] = [{
    modelName: "claude-opus-4-20250514",
    provider: "anthropic",
    displayName: "Claude Opus 4",
    maxInputTokens: 200000,
    maxOutputTokens: 32000,
    thinking: true,
    minThinkingTokens: 1024,
    maxThinkingTokens: 32000,
}, {
    modelName: "claude-sonnet-4-20250514",
    provider: "anthropic",
    displayName: "Claude Sonnet 4",
    maxInputTokens: 200000,
    maxOutputTokens: 64000,
    thinking: true,
    minThinkingTokens: 1024,
    maxThinkingTokens: 64000,
}, {
    modelName: "claude-3-7-sonnet-20250219",
    provider: "anthropic",
    displayName: "Claude Sonnet 3.7",
    maxInputTokens: 200000,
    maxOutputTokens: 64000,
    thinking: true,
    minThinkingTokens: 1024,
    maxThinkingTokens: 128000,
}, {
    modelName: "claude-3-5-sonnet-20241022",
    provider: "anthropic",
    displayName: "Claude Sonnet 3.5 (New)",
    maxInputTokens: 200000,
    maxOutputTokens: 8192,
    thinking: false,
}, {
    modelName: "claude-3-5-haiku-20241022",
    provider: "anthropic",
    displayName: "Claude Haiku 3.5",
    maxInputTokens: 200000,
    maxOutputTokens: 8192,
    thinking: false,
}, {
    modelName: "claude-3-5-sonnet-20240620",
    provider: "anthropic",
    displayName: "Claude Sonnet 3.5 (Old)",
    maxInputTokens: 200000,
    maxOutputTokens: 8192,
    thinking: false,
}, {
    modelName: "claude-3-sonnet-20240229",
    provider: "anthropic",
    displayName: "Claude Sonnet 3",
    maxInputTokens: 200000,
    maxOutputTokens: 4096,
    thinking: false,
}, {
    modelName: "claude-3-haiku-20240307",
    provider: "anthropic",
    displayName: "Claude Haiku 3",
    maxInputTokens: 200000,
    maxOutputTokens: 4096,
    thinking: false,
}, {
    modelName: "claude-3-opus-20240229",
    provider: "anthropic",
    displayName: "Claude Opus 3",
    maxInputTokens: 200000,
    maxOutputTokens: 4096,
    thinking: false,
}];

export const openaiModels: ModelCapabilities[] = [{
    modelName: "o4-mini",
    provider: "openai",
    displayName: "OpenAI o4-mini",
    maxInputTokens: 200000,
    maxOutputTokens: 100000,
    thinking: true,
    minThinkingTokens: 1024,
    maxThinkingTokens: 32000,
}, {
    modelName: "o3",
    provider: "openai",
    displayName: "OpenAI o3",
    maxInputTokens: 200000,
    maxOutputTokens: 100000,
    thinking: true,
    minThinkingTokens: 1024,
    maxThinkingTokens: 32000,
}, {
    modelName: "o3-pro", // does not support /chat/completions endpoint
    provider: "openai",
    displayName: "OpenAI o3-pro",
    maxInputTokens: 200000,
    maxOutputTokens: 100000,
    thinking: true,
    minThinkingTokens: 1024,
    maxThinkingTokens: 32000,
}, {
    modelName: "o3-mini",
    provider: "openai",
    displayName: "OpenAI o3-mini",
    maxInputTokens: 200000,
    maxOutputTokens: 100000,
    thinking: true,
    minThinkingTokens: 1024,
    maxThinkingTokens: 16000,
}, {
    modelName: "gpt-4o-mini",
    provider: "openai",
    displayName: "GPT-4o-mini",
    maxInputTokens: 128000,
    maxOutputTokens: 16384,
    thinking: false,
}];

export const geminiModels: ModelCapabilities[] = [{
    modelName: "gemini-2.5-pro",
    provider: "google",
    displayName: "Gemini 2.5 Pro",
    maxInputTokens: 1048576,
    maxOutputTokens: 65536,
    thinking: true,
    minThinkingTokens: 128,
    maxThinkingTokens: 32768,
}, {
    modelName: "gemini-2.5-flash",
    provider: "google",
    displayName: "Gemini 2.5 Flash",
    maxInputTokens: 1048576,
    maxOutputTokens: 65535,
    thinking: true,
    minThinkingTokens: 0,
    maxThinkingTokens: 24576,
}, {
    modelName: "gemini-2.5-flash-lite-preview-06-17",
    provider: "google",
    displayName: "Gemini 2.5 Flash-Lite",
    maxInputTokens: 1000000,
    maxOutputTokens: 64000,
    thinking: true,
    minThinkingTokens: 512,
    maxThinkingTokens: 24576,
}, {
    modelName: "gemini-2.0-flash",
    provider: "google",
    displayName: "Gemini 2.0 Flash",
    maxInputTokens: 1048576,
    maxOutputTokens: 8192,
    thinking: false,
}];

export const otherModels: ModelCapabilities[] = [{
    modelName: "openrouter/cypher-alpha:free",
    provider: "other",
    displayName: "Cypher Alpha",
    maxInputTokens: 1048576,
    maxOutputTokens: 65536,
    thinking: true,
    minThinkingTokens: 128,
    maxThinkingTokens: 32768,
}, {
    modelName: "mistralai/mistral-small-3.2-24b-instruct:free",
    provider: "other",
    displayName: "Mistral Small 3.2",
    maxInputTokens: 1048576,
    maxOutputTokens: 65536,
    thinking: true,
    minThinkingTokens: 128,
    maxThinkingTokens: 32768,
}];
